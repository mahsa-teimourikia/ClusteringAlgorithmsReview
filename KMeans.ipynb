{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering\n",
    "\n",
    "Clustering is a Machine Learning technique that involves the grouping of data points. Given a set of data points, we can use a clustering algorithm to classify each data point into a specific group. In theory, data points that are in the same group should have similar properties and/or features, while data points in different groups should have highly dissimilar properties and/or features.\n",
    "\n",
    "## K-Means Clustering\n",
    "K-Means is one of the most common clustering algorithms which attempts to group similar clusters together.\n",
    "\n",
    "Typical problems that can be tackled with K-Means are:\n",
    "* Grouping similar documents\n",
    "* Customer profiling\n",
    "* Market segmentation\n",
    "* Identifying similar groups\n",
    "\n",
    "The K-Means algorithm steps are as follows:\n",
    "\n",
    "* Choose a number of clusters $K$\n",
    "* Randomly assign each point to a cluster\n",
    "* Until clusters stop changing, repeat the following:\n",
    "    * For each cluster, compute the cluster centroid by taking the mean vector of the points in the cluster.\n",
    "    * Assign each data point to the cluster for which the centroid is the closest.\n",
    "\n",
    "### Choosing K Value\n",
    "\n",
    "There is no easy way to choose the best K value. One method that is used is the _elbow method_ described below:\n",
    "\n",
    "* Compute the sum of squared error (SSE) for some values of K. (The SSE is defined as the sum of squared distance between each member of the cluster and its centroid.)\n",
    "* By plotting K against SSE, you will see that the error decreases as K gets larger. The reason is that the larger the K, the smaller the clusters and hence the smaller the distortion.\n",
    "* The idea is to choose the K at which the SSE decreases abruptly. This is known as the _Elbow Effect_ in the graph.\n",
    "\n",
    "You can see an example on the image below, where on the x-axis we have the K value and on the y-axis we have the SSE. As can be seen, after K value equal to 6-7 we won't get any further significant improvements on the SSE. Hence the K value can be chosen around those values.\n",
    "\n",
    "<img src=\"images/elbow-effect.JPG\"/>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
